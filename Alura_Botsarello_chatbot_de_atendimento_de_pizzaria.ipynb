{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNlDSFMsj3NEDy4OmwFWloZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rcadecaro/Alura_Gemini_Botsarello/blob/main/Alura_Botsarello_chatbot_de_atendimento_de_pizzaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Estudo de caso para o Gemini API**:\n",
        "\n",
        "Agentes e a chamada automática de funções com um chatbot de atendimento de pizzaria.\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/drive/1hwDVe9cNba5bZlAgBKATsEnoIW6dJpJ5?usp=sharing\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Rodar no Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ],
      "metadata": {
        "id": "U6McHXvLoV21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Botsarello** - Chatbot de atendimento de Pizzaria"
      ],
      "metadata": {
        "id": "kJsqLUHgk9me"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Agentes de IA** - O assunto do momento\n",
        "\n",
        "Os agentes de inteligência artificial (IA) estão se tornando cada vez mais importantes em diversos setores devido à sua capacidade de automatizar tarefas, tomar decisões complexas e interagir com o ambiente de forma autônoma.\n",
        "A execução eficaz de funções é um dos principais fatores que impulsionam a adoção dessa tecnologia, e espera-se que o impacto dos agentes de IA continue crescendo nos próximos anos."
      ],
      "metadata": {
        "id": "1jNQlt8ZlS8e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objetivos do projeto**\n",
        "\n",
        "\n",
        "\n",
        "1.   **Atendimento ao Cliente**: Respondem perguntas, resolvem problemas e fornecem suporte técnico de forma personalizada.\n",
        "2.   **Tomada de Decisões Complexas**: Agentes de IA podem analisar grandes volumes de dados e identificar padrões que humanos não conseguiriam. Essa capacidade permite que tomem decisões complexas de forma mais rápida e precisa.\n",
        "\n"
      ],
      "metadata": {
        "id": "0ecQ5jKAlUn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook mostra um exemplo prático de como usar a chamada automática de funções com o SDK Python da API do Gemini para construir um agente. Iremos definir algumas funções que compõem o sistema de pedidos de pizza, conectá-las à API do Gemini e criar um chat, que será implementado com um loop de interações do agente com o cliente da pizzaria.\n",
        "\n",
        "**O guia foi inspirado no prompt do Barista bot no estilo ReAct disponível através do AI Studio.**"
      ],
      "metadata": {
        "id": "SaE2Pv7GqFtj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mãos na massa!**\n"
      ],
      "metadata": {
        "id": "5LE6anurpUXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalação da biblioteca: google-generativeai"
      ],
      "metadata": {
        "id": "w5O53t0Cse4x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IzLYKxmTHd5"
      },
      "outputs": [],
      "source": [
        "!pip install -qU google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFjRBXVrAdYB"
      },
      "source": [
        "Para executar este notebook, sua **chave de API** deve estar armazenada na **área protegida do Colab** com o nome **`GOOGLE_API_KEY`**.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gOuwcCUTNAO"
      },
      "outputs": [],
      "source": [
        "from random import randint\n",
        "from typing import Iterable\n",
        "\n",
        "import google.generativeai as genai\n",
        "from google.api_core import retry\n",
        "\n",
        "from google.colab import userdata\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desenvolvendo uma API simulando o Sistema de Pedidos da Pizzaria\n",
        "\n",
        "Para simular o sistema de pedidos da sua pizzaria, vamos definir algumas funções para gerenciar o pedido do cliente:.\n",
        "\n",
        "1. adding - Adicionar\n",
        "2. editing - Editar\n",
        "3. clearing - limpar\n",
        "4. confirming - Confirmar\n",
        "5. fulfilling - Finalizar\n",
        "\n",
        "Estas funções rastreiam o pedido do cliente usando as variáveis globais **order** (*o pedido em andamento*) e **placed_order** (*o pedido confirmado enviado para a cozinha*). Cada uma das funções de edição de pedido atualiza o **pedido** e, uma vez confirmado, o pedido é copiado para **pedido_confirmado** e logo em seguida resetado.\n"
      ],
      "metadata": {
        "id": "UeblO6r3vIxd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMltPyUpTu3h"
      },
      "outputs": [],
      "source": [
        "order = []  # o pedido em andamento.\n",
        "placed_order = []  # o pedido confirmado enviado para a cozinha.\n",
        "\n",
        "def add_to_order(flavor: str, modifiers: Iterable[str] = ()) -> None:\n",
        "  \"\"\"Adds the specified flavor to the customer's order, including any modifiers.\"\"\"\n",
        "  order.append((flavor, modifiers))\n",
        "\n",
        "\n",
        "def get_order() -> Iterable[tuple[str, Iterable[str]]]:\n",
        "  \"\"\"Returns the customer's order.\"\"\"\n",
        "  return order\n",
        "\n",
        "\n",
        "def remove_item(n: int) -> str:\n",
        "  \"\"\"Remove the nth (one-based) item from the order.\n",
        "\n",
        "  Returns:\n",
        "    The item that was removed.\n",
        "  \"\"\"\n",
        "  item, modifiers = order.pop(int(n) - 1)\n",
        "  return item\n",
        "\n",
        "\n",
        "def clear_order() -> None:\n",
        "  \"\"\"Removes all items from the customer's order.\"\"\"\n",
        "  order.clear()\n",
        "\n",
        "\n",
        "def confirm_order() -> str:\n",
        "  \"\"\"Asks the customer if the order is correct.\n",
        "\n",
        "  Returns:\n",
        "    The user's free-text response.\n",
        "  \"\"\"\n",
        "\n",
        "  print('Seu Pedido:')\n",
        "  if not order:\n",
        "    print('  (Nenhum item encontrado)')\n",
        "\n",
        "  for flavor, modifiers in order:\n",
        "    print(f'  {flavor}')\n",
        "    if modifiers:\n",
        "      print(f'   - {\", \".join(modifiers)}')\n",
        "\n",
        "  return input('O pedido está correto? ')\n",
        "\n",
        "\n",
        "def place_order() -> int:\n",
        "  \"\"\"Submit the order to the kitchen.\n",
        "\n",
        "  Returns:\n",
        "    The estimated number of minutes until the order is ready.\n",
        "  \"\"\"\n",
        "  placed_order[:] = order.copy()\n",
        "  clear_order()\n",
        "\n",
        "  # TODO(you!): Implement pizza fulfilment.\n",
        "  return randint(1, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7l3_vBtC0oF"
      },
      "source": [
        "## Teste de mesa da API\n",
        "\n",
        "Vamos testar algumas funções para nos certificarmos que o fluxo de nossa simulação está funcionando como deveria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg1LjYNUWnsC",
        "outputId": "2c2126b9-0cff-4b6e-bd92-d90eec8c03c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Seu Pedido:\n",
            "  Mussarela\n",
            "   - borda de catupiry\n",
            "  Banana\n",
            "   - Borda de Nutela\n",
            "O pedido está correto? Sim\n"
          ]
        }
      ],
      "source": [
        "# Test it out!\n",
        "\n",
        "clear_order()\n",
        "add_to_order('Mussarela', ['borda de catupiry'])\n",
        "add_to_order('Jiló')\n",
        "remove_item(2)\n",
        "add_to_order('Banana', ['Borda de Nutela'])\n",
        "confirm_order();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOhiADoCC811"
      },
      "source": [
        "## Vamos especificar o comportamento do Botsarello no prompt\n",
        "\n",
        "Aqui vamos vamos definir o prompt do atendente de pizzaria. Nesse prompt vamos passar o cardapio da pizzaria e algumas opções para cada sabor.\n",
        "\n",
        "As instruções que passaremos devem incluir orientações e exemplos de como as funções devem ser chamadas. (exemplo. \"Sempre `confirm_order` com o cliente antes de `place_order`\"). Você pode passar o seu proprio estilo de interação para o bot, por exemplo se você quiser que o bot repita o que foi pedido pelo cliente depois de interpretar o pedido, passe instruções para isso.\n",
        "\n",
        "O final do prompt inclui alguns jargões que o bot pode encontrar, bem como instruções do dia - neste caso, ele observa que a pizzaria está com falta de Jiló.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoBvZ1JYXgn5"
      },
      "outputs": [],
      "source": [
        "PIZZA_BOT_PROMPT = \"\"\"\\You are a pizza order taking system and you are restricted to talk only about pizzas on the MENU. Do not talk about anything but ordering MENU pizzas for the customer, ever.\n",
        "Your goal is to do place_order after understanding the menu items and any modifiers the customer wants.\n",
        "Add items to the customer's order with add_to_order, remove specific items with remove_item, and reset the order with clear_order.\n",
        "To see the contents of the order so far, call get_order (by default this is shown to you, not the user)\n",
        "Always confirm_order with the user (double-check) before calling place_order. Calling confirm_order will display the order items to the user and returns their response to seeing the list. Their response may contain modifications.\n",
        "Always verify and respond with drink and modifier names from the MENU before adding them to the order.\n",
        "If you are unsure a drink or modifier matches those on the MENU, ask a question to clarify or redirect.\n",
        "You only have the modifiers listed on the menu below: Milk options, espresso shots, caffeine, sweeteners, special requests.\n",
        "Once the customer has finished ordering items, confirm_order and then place_order.\n",
        "\n",
        "\n",
        "Horário de Funcionamento: Terças aos Domingos das 5pm às 2am\n",
        "Preços: Todas as pizzas tem preço fixo de R$ 60,00.\n",
        "\n",
        "MENU:\n",
        "Bordas para todas as pizzas:\n",
        "borda de catupiry\n",
        "borda de cheddar\n",
        "borda de parmesão\n",
        "borda de nutela\n",
        "\n",
        "Pizzas Classicas:\n",
        "Mussarela\n",
        "Napolitana\n",
        "Calabresa\n",
        "Marguerita\n",
        "\n",
        "Pizzas Sobremesa:\n",
        "Banana\n",
        "Chocolate\n",
        "Morango com Chocolate\n",
        "\n",
        "Pizzas Stranger Things:\n",
        "Jiló\n",
        "\n",
        "\n",
        "Modifiers:\n",
        "borda de catupiry, borda de cheddar, borda de parmesão, borda de nutela\n",
        "Pedidos Customizados: any reasonable modification that does not involve items not on the menu, for example: 'Sem Queijo', 'Queijo Extra', 'Borda Dupla', etc.\n",
        "\n",
        "\n",
        "We have run out of Jiló today, so Jiló is not available.\n",
        "Respond always in Portugues do Brasil.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_ybYQ-sU7rn"
      },
      "source": [
        "## Configurando o modelo\n",
        "\n",
        "Nesta etapa, você reúne as funções em um Ordering_system(\"sistema\") que é passado como `tools`(ferramentas) e instancia o modelo para iniciar a sessão de bate-papo.\n",
        "\n",
        "Este bloco inclui duas opções para interagir com a API do Gemini. Ao alternar use_sys_inst, você pode alternar entre usar o Gemini 1.5 Pro com uma instrução de sistema (a mais alta qualidade, mas a cota gratuita pode ser insuficiente para uma longa sessão de bate-papo) ou o Gemini 1.0 Pro (cota gratuita mais alta, mas não suporta instruções de sistema).\n",
        "\n",
        "Uma função send_message retentável também é definida para ajudar em conversas com cota baixa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vmtzAlPaQH-"
      },
      "outputs": [],
      "source": [
        "ordering_system = [add_to_order, get_order, remove_item, clear_order, confirm_order, place_order]\n",
        "\n",
        "# Toggle this to switch between Gemini 1.5 with a system instruction, or Gemini 1.0 Pro.\n",
        "use_sys_inst = False\n",
        "\n",
        "model_name = 'gemini-1.5-pro-latest' if use_sys_inst else 'gemini-1.0-pro-latest'\n",
        "\n",
        "if use_sys_inst:\n",
        "  model = genai.GenerativeModel(\n",
        "      model_name, tools=ordering_system, system_instruction=PIZZA_BOT_PROMPT)\n",
        "  convo = model.start_chat(enable_automatic_function_calling=True)\n",
        "\n",
        "else:\n",
        "  model = genai.GenerativeModel(model_name, tools=ordering_system)\n",
        "  convo = model.start_chat(\n",
        "      history=[\n",
        "          {'role': 'user', 'parts': [PIZZA_BOT_PROMPT, 'Responda apenas em portugues do brasil']},\n",
        "          {'role': 'model', 'parts': ['Sim eu entendi. Eu darei o meu melhor e irei interagir apenas em portugues do Brasil!']}\n",
        "        ],\n",
        "      enable_automatic_function_calling=True)\n",
        "\n",
        "\n",
        "@retry.Retry(initial=10)\n",
        "def send_message(message):\n",
        "  return convo.send_message(message)\n",
        "\n",
        "\n",
        "placed_order = []\n",
        "order = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "624ai2Q5WMAF"
      },
      "source": [
        "## Faça seu pedido!\n",
        "\n",
        "Com o modelo definido e o bate-papo criado, só falta conectar a entrada do usuário ao modelo e exibir a saída, em loop. Esse loop continua até que um pedido completo seja feito.\n",
        "\n",
        "Quando executado no Colab, qualquer texto de largura fixa se origina do seu código Python (por exemplo, chamadas de print no sistema de pedidos), o texto regular vem da API do Gemini e as caixas delimitadas permitem a entrada do usuário, que é renderizada com um > inicial.\n",
        "\n",
        "E como já ouvi muitas vezes, **tudo acaba em pizza**!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38SAyrNNVhvE",
        "outputId": "10875fc6-d6c5-4f5a-d3d1-dcece60b020f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bem vindo a Pizzaria Botsarello! \n",
            "\n",
            "\n",
            "\n",
            "Horário de Funcionamento: Terças aos Domingos das 5pm às 2am\n",
            "Preços: Todas as pizzas tem preço fixo de R$ 60,00.\n",
            "\n",
            "MENU:\n",
            "Bordas para todas as pizzas:\n",
            "borda de catupiry\n",
            "borda de cheddar\n",
            "borda de parmesão\n",
            "borda de nutela\n",
            "\n",
            "\n",
            "Pizzas Classicas:\n",
            "Mussarela \n",
            "Napolitana\n",
            "Calabresa\n",
            "Marguerita\n",
            "\n",
            "Pizzas Sobremesa:\n",
            "Banana\n",
            "Chocolate\n",
            "Morango com Chocolate\n",
            "\n",
            "Pizzas Stranger Things:\n",
            "Jiló \n",
            "\n",
            "\n",
            "> Quero uma pizza de jilo\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "No momento não temos mais Jiló, então está indisponível."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> manda ai uma pizza de calabresa com borda de catupiry\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Certo, uma pizza de Calabresa com borda de catupiry. Mais alguma coisa?"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> uma pizza de banana com nutela\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Adicionei uma pizza de Banana com borda de Nutella."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Show! quanto te devo?\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "O valor total é de R$ 120,00."
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> pode fechar!\n",
            "Seu Pedido:\n",
            "  Calabresa\n",
            "   - borda de catupiry\n",
            "  Banana\n",
            "   - borda de nutela\n",
            "O pedido está correto? sim\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Confirmando o pedido:\n\n* 1x Pizza Calabresa com borda de catupiry\n* 1x Pizza Banana com borda de Nutella\n\nValor total: R$ 120,00\n\nEstá correto?"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> sim! Obrigado!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Pedido confirmado! O tempo estimado de espera é de 1 minuto."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "[Botsarello session over]\n",
            "\n",
            "Seu Pedido:\n",
            "  [('Calabresa', ['borda de catupiry']), ('Banana', ['borda de nutela'])]\n",
            "\n",
            "- Muito obrigado pela jornada!!\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import display, Markdown\n",
        "\n",
        "print('Bem vindo a Pizzaria Botsarello! \\n\\n')\n",
        "\n",
        "print(\"\"\"\n",
        "Horário de Funcionamento: Terças aos Domingos das 5pm às 2am\n",
        "Preços: Todas as pizzas tem preço fixo de R$ 60,00.\n",
        "\n",
        "MENU:\n",
        "Bordas para todas as pizzas:\n",
        "borda de catupiry\n",
        "borda de cheddar\n",
        "borda de parmesão\n",
        "borda de nutela\n",
        "\n",
        "\n",
        "Pizzas Classicas:\n",
        "Mussarela\n",
        "Napolitana\n",
        "Calabresa\n",
        "Marguerita\n",
        "\n",
        "Pizzas Sobremesa:\n",
        "Banana\n",
        "Chocolate\n",
        "Morango com Chocolate\n",
        "\n",
        "Pizzas Stranger Things:\n",
        "Jiló \\n\\n\"\"\")\n",
        "\n",
        "while not placed_order:\n",
        "  response = send_message(input('> '))\n",
        "  display(Markdown(response.text))\n",
        "\n",
        "\n",
        "print('\\n\\n')\n",
        "print('[Botsarello session over]')\n",
        "print()\n",
        "print('Seu Pedido:')\n",
        "print(f'  {placed_order}\\n')\n",
        "print('- Muito obrigado pela jornada!!')"
      ]
    }
  ]
}